{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quant-econ Solutions: Rational Expectations Equilibrium\n",
    "\n",
    "Solutions for http://quant-econ.net/jl/rational_expectations.html\n",
    "\n",
    "The following solutions were put together by Chase Coleman, Spencer Lyon, Thomas Sargent and John Stachurski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using QuantEcon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To map a problem into a [discounted optimal linear control problem](http://quant-econ.net/jl/lqcontrol.html), we need to define\n",
    "\n",
    "* state vector $x_t$ and control vector $u_t$\n",
    "\n",
    "* matrices $A, B, Q, R$ that define preferences and the law of motion for the state\n",
    "\n",
    "For the state and control vectors we choose\n",
    "\n",
    "$$\n",
    "    x_t = \\begin{bmatrix} y_t \\\\ Y_t \\\\ 1 \\end{bmatrix},\n",
    "    \\qquad\n",
    "    u_t = y_{t+1} - y_{t}\n",
    "$$\n",
    "\n",
    "For $, B, Q, R$ we set\n",
    "\n",
    "$$\n",
    "    A = \n",
    "    \\begin{bmatrix} \n",
    "        1 & 0 & 0 \\\\\n",
    "        0 & \\kappa_1 & \\kappa_0 \\\\ \n",
    "        0 & 0 & 1 \n",
    "    \\end{bmatrix},\n",
    "    \\quad\n",
    "    B = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} ,\n",
    "    \\quad\n",
    "    R = \n",
    "    \\begin{bmatrix} \n",
    "        0 & a_1/2 & -a_0/2 \\\\ \n",
    "        a_1/2 & 0 & 0 \\\\ \n",
    "        -a_0/2 & 0 & 0 \n",
    "    \\end{bmatrix},\n",
    "    \\quad\n",
    "    Q = \\gamma / 2\n",
    "$$\n",
    "\n",
    "By multiplying out you can confirm that\n",
    "\n",
    "* $x_t' R x_t + u_t' Q u_t = - r_t$\n",
    "\n",
    "* $x_{t+1} = A x_t + B u_t$\n",
    "\n",
    "We'll use the module  ``lqcontrol.py`` to solve the firm's problem at the stated parameter values\n",
    "\n",
    "This will return an LQ policy $F$ with the interpretation $u_t = - F x_t$, or\n",
    "\n",
    "$$\n",
    "    y_{t+1} - y_t = - F_0 y_t - F_1 Y_t - F_2\n",
    "$$\n",
    "\n",
    "Matching parameters with $y_{t+1} = h_0 + h_1 y_t + h_2 Y_t$ leads to\n",
    "\n",
    "$$\n",
    "    h_0 = -F_2, \\quad h_1 = 1 - F_0, \\quad h_2 = -F_1\n",
    "$$\n",
    "\n",
    "Here's our solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = [-0.000, 0.046, -96.949]\n",
      "(h1, h2, h3) = [96.949, 1.000, -0.046]\n"
     ]
    }
   ],
   "source": [
    "# == Model parameters == #\n",
    "a0      = 100\n",
    "a1      = 0.05\n",
    "bet     = 0.95\n",
    "gamma   = 10.0\n",
    "\n",
    "# == Beliefs == #\n",
    "kappa0  = 95.5\n",
    "kappa1  = 0.95\n",
    "\n",
    "# == Formulate the LQ problem == #\n",
    "A = [1 0 0\n",
    "     0 kappa1 kappa0\n",
    "     0 0 1]\n",
    "B = [1.0, 0.0, 0.0]\n",
    "R = [0 a1/2 -a0/2\n",
    "     a1/2 0 0\n",
    "     -a0/2 0 0]\n",
    "Q = 0.5 * gamma\n",
    "\n",
    "# == Solve for the optimal policy == #\n",
    "lq = LQ(Q, R, A, B, nothing, bet)\n",
    "P, F, d = stationary_values(lq)\n",
    "\n",
    "hh = h0, h1, h2 = -F[3], 1 - F[1], -F[2]\n",
    "\n",
    "@printf(\"F = [%.3f, %.3f, %.3f]\\n\", F[1], F[2], F[3])\n",
    "@printf(\"(h1, h2, h3) = [%.3f, %.3f, %.3f]\\n\", h0, h1, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implication is that\n",
    "\n",
    "$$\n",
    "    y_{t+1} = 96.949 + y_t - 0.046 \\, Y_t\n",
    "$$\n",
    "\n",
    "\n",
    "For the case $n > 1$, recall that $Y_t = n y_t$, which, combined with the previous equation, yields\n",
    "\n",
    "$$\n",
    "    Y_{t+1} \n",
    "    = n \\left( 96.949 + y_t - 0.046 \\, Y_t \\right)  \n",
    "    = n 96.949 + (1 - n 0.046) Y_t \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "To determine whether a $\\kappa_0, \\kappa_1$ pair forms the\n",
    "aggregate law of motion component of a rational expectations equilibrium, we\n",
    "can proceed as follows:\n",
    "\n",
    "* Determine the corresponding firm law of motion $y_{t+1} = h_0 + h_1 y_t + h_2 Y_t$\n",
    "\n",
    "* Test whether the associated aggregate law :$Y_{t+1} = n h(Y_t/n, Y_t)$ evaluates to $Y_{t+1} = \\kappa_0 + \\kappa_1 Y_t$\n",
    "\n",
    "In the second step we can use $Y_t = n y_t = y_t$, so that $Y_{t+1} = n h(Y_t/n, Y_t)$ becomes\n",
    "\n",
    "$$\n",
    "    Y_{t+1} = h(Y_t, Y_t) = h_0 + (h_1 + h_2) Y_t\n",
    "$$\n",
    "\n",
    "Hence to test the second step we can test $\\kappa_0 = h_0$ and $\\kappa_1 = h_1 + h_2$\n",
    "\n",
    "The following code implements this test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrium pair= (95.081845, 0.952459)\n",
      "(h1, h2, h3) = [95.081891, 1.000000, -0.047541]\n"
     ]
    }
   ],
   "source": [
    "candidates = ([94.0886298678, 0.923409232937],\n",
    "              [93.2119845412, 0.984323478873],\n",
    "              [95.0818452486, 0.952459076301])\n",
    "\n",
    "for (k0, k1) in candidates\n",
    "    A = [1 0 0\n",
    "         0 k1 k0\n",
    "         0 0 1]\n",
    "    lq = LQ(Q, R, A, B, nothing, bet)\n",
    "    P, F, d = stationary_values(lq)\n",
    "    hh = h0, h1, h2 = -F[3], 1 - F[1], -F[2]\n",
    "    \n",
    "    if isapprox(k0, h0) && isapprox(k1, h1 + h2)\n",
    "        @printf(\"Equilibrium pair= (%.6f, %.6f)\\n\", k0, k1)\n",
    "        @printf(\"(h1, h2, h3) = [%.6f, %.6f, %.6f]\\n\", h0, h1, h2)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells us that the answer is pair (iii), which implies $(h_0, h_1, h_2) = (95.0819, 1.0000, -.0475)$\n",
    "\n",
    "(Notice we use `np.allclose` to test equality of floating point numbers, since exact equality is too strict)\n",
    "\n",
    "Regarding the iterative algorithm, one could loop from a given\n",
    "$(\\kappa_0, \\kappa_1)$ pair to the associated firm law and then to a new $(\\kappa_0, \\kappa_1)$ pair\n",
    "\n",
    "This amounts to implementing the operator $\\Phi$ described in the lecture\n",
    "\n",
    "(There is in general no guarantee that this iterative process will converge to\n",
    "a rational expectations equilibrium)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "We are asked to write the planner problem as an LQ problem \n",
    "\n",
    "For the state and control vectors we choose\n",
    "\n",
    "$$\n",
    "    x_t = \\begin{bmatrix} Y_t \\\\ 1 \\end{bmatrix},\n",
    "    \\quad\n",
    "    u_t = Y_{t+1} - Y_{t}\n",
    "$$\n",
    "\n",
    "For the LQ matrices we set\n",
    "\n",
    "$$\n",
    "    A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix},\n",
    "    \\quad\n",
    "    B = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\n",
    "    \\quad\n",
    "    R = \\begin{bmatrix} a_1/2 & -a_0/2 \\\\ -a_0/2 & 0 \\end{bmatrix},\n",
    "    \\quad\n",
    "    Q = \\gamma / 2\n",
    "$$\n",
    "\n",
    "By multiplying out you can confirm that\n",
    "\n",
    "* $x_t' R x_t + u_t' Q u_t = - s(Y_t, Y_{t+1})$\n",
    "\n",
    "* $x_{t+1} = A x_t + B u_t$\n",
    "\n",
    "By obtaining the optimal policy and using $u_t = - F x_t$ or\n",
    "\n",
    "$$\n",
    "    Y_{t+1} - Y_t = -F_0 Y_t - F_1 \n",
    "$$\n",
    "\n",
    "we can obtain the implied aggregate law of motion via $\\kappa_0 = -F_1$\n",
    "and $\\kappa_1 = 1-F_0$\n",
    "\n",
    "The Python code to solve this problem is below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa0=95.08187459215024\tkappa1=0.9524590627039249\n"
     ]
    }
   ],
   "source": [
    "# == Formulate the planner's LQ problem == #\n",
    "A = eye(2)\n",
    "B = [1.0, 0.0]\n",
    "R = [a1 / 2.0 -a0 / 2.0\n",
    "     -a0 / 2.0 0.0]\n",
    "Q = gamma / 2.0\n",
    "\n",
    "# == Solve for the optimal policy == #\n",
    "lq = LQ(Q, R, A, B, nothing, bet)\n",
    "P, F, d = stationary_values(lq)\n",
    "\n",
    "# == Print the results == #\n",
    "kappa0, kappa1 = -F[2], 1 - F[1]\n",
    "println(\"kappa0=$kappa0\\tkappa1=$kappa1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output yields the same $(\\kappa_0, \\kappa_1)$ pair obtained as an equilibrium from the previous exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "The monopolist's LQ problem is almost identical to the planner's problem from\n",
    "the previous exercise, except that\n",
    "\n",
    "$$\n",
    "    R = \\begin{bmatrix} \n",
    "        a_1 & -a_0/2 \\\\ \n",
    "        -a_0/2 & 0 \n",
    "    \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "The problem can be solved as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0=73.47294403502895\tm1=0.9265270559649711\n"
     ]
    }
   ],
   "source": [
    "# == Formulate the monopolist's LQ problem == #\n",
    "A = eye(2)\n",
    "B = [1.0, 0.0]\n",
    "R = [a1 -a0 / 2.0\n",
    "     -a0 / 2.0 0.0]\n",
    "Q = gamma / 2.0\n",
    "\n",
    "# == Solve for the optimal policy == #\n",
    "lq = LQ(Q, R, A, B, nothing, bet)\n",
    "P, F, d = stationary_values(lq)\n",
    "\n",
    "# == Print the results == #\n",
    "m0, m1 = -F[2], 1 - F[1]\n",
    "println(\"m0=$m0\\tm1=$m1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the law of motion for the monopolist is approximately $Y_{t+1} = 73.4729 + 0.9265 Y_t$\n",
    "\n",
    "In the rational expectations case the law of motion was approximately\n",
    "$Y_{t+1} = 95.0818 + 0.9525 Y_t$\n",
    "\n",
    "One way to compare these two laws of motion is by their fixed points, which give long run equilibrium output in each case\n",
    "\n",
    "For laws of the form $Y_{t+1} = c_0 + c_1 Y_t$, the fixed point is $c_0 / (1 - c_1)$\n",
    "\n",
    "If you crunch the numbers, you will see that the monopolist adopts a lower long run\n",
    "quantity than obtained by the competitive market, implying a higher market price\n",
    "\n",
    "This is analogous to the elementary static-case results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0-dev",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
